{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data_features = pd.read_csv(\"/kaggle/input/dengai-dataset/DengAI_Predicting_Disease_Spread_-_Training_Data_Features.csv\")\ntrain_data_features['cases'] = pd.read_csv(\"/kaggle/input/dengai-dataset/DengAI_Predicting_Disease_Spread_-_Training_Data_Labels.csv\", usecols=[3])\ntest_data_features = pd.read_csv(\"/kaggle/input/dengai-dataset/DengAI_Predicting_Disease_Spread_-_Test_Data_Features.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_data_features.isnull().sum()/len(train_data_features))*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(test_data_features.isnull().sum()/len(test_data_features))*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_features.interpolate(method='linear', limit_direction='forward', axis=0, inplace=True)\ntest_data_features.interpolate(method='linear', limit_direction='forward', axis=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation_heatmap(train):\n    correlations = train.corr()\n\n    fig, ax = plt.subplots(figsize=(15,15))\n    sns.heatmap(correlations, vmax=1.0, center=0, fmt='.2f',\n                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .70})\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ndvi_variables = train_data_features[['ndvi_ne', 'ndvi_nw', 'ndvi_sw', 'ndvi_se']]\ncorrelation_heatmap(ndvi_variables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precipitation_variables = train_data_features[['precipitation_amt_mm', 'reanalysis_sat_precip_amt_mm', 'station_precip_mm']]\ncorrelation_heatmap(precipitation_variables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max_scaler = preprocessing.MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temperature = train_data_features[['reanalysis_air_temp_k', 'reanalysis_avg_temp_k','reanalysis_dew_point_temp_k',\n                                  'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k','reanalysis_tdtr_k','station_avg_temp_c',\n                                   'station_diur_temp_rng_c', 'station_max_temp_c','station_min_temp_c']]\ntemperature = min_max_scaler.fit_transform(temperature)\ntemperature = pd.DataFrame(temperature)\ncorrelation_heatmap(temperature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = train_data_features.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [c for c in upper.columns if any(upper[c] > 0.98)]\ndel upper\n\nprint('drop SIMILAR columns:', to_drop)\ntrain_data_features.drop(to_drop,1,inplace=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}